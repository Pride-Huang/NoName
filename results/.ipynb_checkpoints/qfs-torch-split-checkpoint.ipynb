{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae582bf-ed58-4c92-ad92-4f389280a1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangzhihao/anaconda3/envs/QSSL/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from itertools import product\n",
    "from CLLoss import *\n",
    "\n",
    "\n",
    "num_qubits = 9\n",
    "\n",
    "w_dim = 3\n",
    "layer_type = 'Basis'\n",
    "cl_loss = 'Distance'\n",
    "cl_loss_weight = 0.08\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "\n",
    "# dev = qml.device(\"lightning.gpu\", wires=num_qubits)\n",
    "def layer_basis(W):\n",
    "    n = W.shape[0]\n",
    "    # print('n='+str(W.shape))\n",
    "    for i in range(n):\n",
    "        qml.Rot(W[i, 0], W[i, 1], W[i, 2], wires=i)\n",
    "    \n",
    "    for i in range(n):\n",
    "        qml.CNOT(wires=[i, (i+1)%n])\n",
    "\n",
    "def layer_CRX(W):\n",
    "    n = W.shape[0]\n",
    "    \n",
    "    # print('n='+str(W.shape))\n",
    "    for i in range(n):\n",
    "        qml.Rot(W[i, 0], W[i, 1], W[i, 2], wires=i)\n",
    "    \n",
    "    for i in range(n):\n",
    "        qml.CRX(W[i, 3],wires=[i, (i+1)%n])\n",
    "\n",
    "        \n",
    "def layer_SSL(W):\n",
    "    n = W.shape[0]\n",
    "    # print('n='+str(W.shape))\n",
    "    for i in range(n):\n",
    "        qml.RY(W[i, 0], wires=i)\n",
    "    \n",
    "    for i in range(n):\n",
    "        qml.CRX(W[i, 1],wires=[i, (i+1)%n])\n",
    "        \n",
    "def layer_iSWAP(W):\n",
    "    n = W.shape[0]\n",
    "    for i in range(n):\n",
    "        qml.ISWAP(wires=[i, (i+1)%n])\n",
    "    # print('n='+str(W.shape))\n",
    "    for i in range(n):\n",
    "        qml.Rot(W[i, 0], W[i, 1], W[i, 2], wires=i)\n",
    "    \n",
    "    for i in range(n):\n",
    "        qml.ISWAP(wires=[(2*n-i-2)%n, (2*n-i-1)%n])\n",
    "        \n",
    "def layer_select(layer_type):\n",
    "    if layer_type=='SSL':\n",
    "        return layer_SSL\n",
    "    elif layer_type=='Basis':\n",
    "        return layer_basis\n",
    "    elif layer_type=='CRX':\n",
    "        return layer_CRX\n",
    "    elif layer_type=='iSWAP':\n",
    "        return layer_iSWAP \n",
    "    \n",
    "def FRQI(input_data, num_qubits, gammas):\n",
    "    location_strings = np.array([i for i in product([0, 1], repeat=num_qubits-1)])\n",
    "    location_wires = [i for i in range(num_qubits-1)]\n",
    "    target_wire = num_qubits-1\n",
    "    # environment_wire = num_qubits-1\n",
    "    \n",
    "    for i in range(num_qubits-1):\n",
    "        qml.Hadamard(i)\n",
    "    \n",
    "    for i in range(input_data.shape[0]):\n",
    "        qml.ctrl(qml.RY, control=location_wires, control_values=location_strings[i])(input_data[i], target_wire)\n",
    "        qml.ctrl(qml.RZ, control=location_wires, control_values=location_strings[i])(gammas[i], target_wire)\n",
    "        # qml.AmplitudeDamping(gamma, target_wire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0ada47-ac63-4052-94f0-42dea4e4e00e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tensor([0.4000, 0.7500, 0.2000, 0.0500], dtype=torch.float64), Y = -1\n",
      "X = tensor([0.3000, 0.5000, 0.2000, 0.0500], dtype=torch.float64), Y = -1\n",
      "X = tensor([0.2000, 0.6000, 0.1500, 0.0500], dtype=torch.float64), Y = -1\n",
      "X = tensor([0.1500, 0.5500, 0.2500, 0.0500], dtype=torch.float64), Y = -1\n",
      "X = tensor([0.3500, 0.8000, 0.2000, 0.0500], dtype=torch.float64), Y = -1\n",
      "...\n",
      "d1=tensor([0.4714, 0.5286], dtype=torch.float64, grad_fn=<ReshapeAliasBackward0>)\n",
      "d2=tensor([0.4714, 0.5286], dtype=torch.float64, grad_fn=<ReshapeAliasBackward0>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "@qml.qnode(dev, interface='torch')#, diff_method=\"backprop\")#interface=\"autograd\")\n",
    "def circuit(weights, gammas, x):\n",
    "    global num_qubits, layer_type\n",
    "    FRQI(x, num_qubits, gammas)\n",
    "    # qml.BasicEntanglerLayers(weights[:,0], wires=range(num_qubits))\n",
    "    \n",
    "    for W in weights:\n",
    "        layer_select(layer_type)(W)\n",
    "        # layer_SSL(W)\n",
    "\n",
    "    # res = qml.expval(qml.PauliZ(0)),qml.expval(qml.PauliZ(1))\n",
    "    # return res\n",
    "    # density = qml.density_matrix(wires=[0,1])\n",
    "    # probs = qml.probs(wires=[i for i in range(num_qubits)])\n",
    "    probs = qml.probs(wires=[0])\n",
    "    return probs\n",
    "    \n",
    "\n",
    "data = np.loadtxt(\"./data/iris_classes1and2_scaled.txt\", delimiter=' ')\n",
    "X = torch.tensor(data[:, :-1], requires_grad=False)\n",
    "Y = data[:, -1]\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"X = {}, Y = {: d}\".format(X[i], int(Y[i])))\n",
    "\n",
    "print(\"...\")\n",
    "                      \n",
    "# np.random.seed(0)\n",
    "# num_qubits = 3\n",
    "num_layers = 6\n",
    "weights_init = 0.1 * torch.rand(num_layers, num_qubits, w_dim, requires_grad=True)\n",
    "gammas = 0.1 * torch.rand(X[0,:].shape[0], requires_grad=False)\n",
    "zeros = torch.zeros(X[0,:].shape[0], requires_grad=False)\n",
    "\n",
    "d1 = circuit(weights=weights_init, gammas=gammas, x=X[0,:])\n",
    "d2 = circuit(weights=weights_init, gammas=zeros, x=X[0,:])\n",
    "print('d1='+str(d1))\n",
    "print('d2='+str(d2))\n",
    "# print('diff='+str(d1-d2))\n",
    "\n",
    "print(type(d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae21020c-c5f9-4941-9651-388de36dbe7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import autoray as ar\n",
    "import torch.nn as nn\n",
    "import math\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# from tqdm import tqdm\n",
    "\n",
    "def info_nce_loss(features, n_view, n_sample):\n",
    "    # print('n_sample='+str(n_sample))\n",
    "    # features = ar.numpy.asarray(features, like=\"torch\")#(features)\n",
    "    labels = torch.cat([torch.arange(n_sample) for i in range(n_view)], dim=0)\n",
    "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "    # print('labels0='+str(labels.shape))\n",
    "    # print(labels)\n",
    "    # print('features='+str(features.shape))\n",
    "    # features = F.normalize(features, dim=1)\n",
    "\n",
    "    similarity_matrix = np.dot(features, features.T)\n",
    "    # print('similarity_matrix='+str(similarity_matrix.shape))\n",
    "    # assert similarity_matrix.shape == (\n",
    "    #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
    "    # assert similarity_matrix.shape == labels.shape\n",
    "    # print(np.where(labels==1))\n",
    "    # discard the main diagonal from both: labels and similarities matrix\n",
    "    mask = torch.eye(labels.shape[0], dtype=torch.bool)\n",
    "    labels = labels[~mask].reshape(labels.shape[0], -1)\n",
    "    # print('labels='+str(labels.shape))\n",
    "    similarity_matrix = similarity_matrix[~mask].reshape(similarity_matrix.shape[0], -1)\n",
    "    # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "    # select and combine multiple positives\n",
    "    positives = similarity_matrix[labels.bool()].reshape(labels.shape[0], -1)\n",
    "    # print('positives='+str(positives.shape))\n",
    "    # select only the negatives the negatives\n",
    "    negatives = similarity_matrix[~labels.bool()].reshape(similarity_matrix.shape[0], -1)\n",
    "    # print('negatives='+str(negatives.shape))\n",
    "    \n",
    "    logits = np.concatenate([positives, negatives], axis=1)\n",
    "    labels = np.zeros(logits.shape[0])\n",
    "\n",
    "    logits = logits / 0.10\n",
    "    # print('logits='+str(logits.shape))\n",
    "    # print('labels='+str(labels.shape))\n",
    "    return logits, labels\n",
    "\n",
    "def info_nce_loss_torch(features, n_views, batch_size):\n",
    "    features = torch.from_numpy(features)\n",
    "    labels = torch.cat([torch.arange(batch_size) for i in range(n_views)], dim=0)\n",
    "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "    # labels = labels.to(self.args.device)\n",
    "\n",
    "    features = F.normalize(features, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(features, features.T)\n",
    "    # assert similarity_matrix.shape == (\n",
    "    #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
    "    # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "    # discard the main diagonal from both: labels and similarities matrix\n",
    "    mask = torch.eye(labels.shape[0], dtype=torch.bool)\n",
    "    labels = labels[~mask].view(labels.shape[0], -1)\n",
    "    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "    # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "    # select and combine multiple positives\n",
    "    positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "    # select only the negatives the negatives\n",
    "    negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "    logits = torch.cat([positives, negatives], dim=1)\n",
    "    labels = torch.zeros(logits.shape[0], dtype=torch.long)\n",
    "\n",
    "    logits = logits / 0.1\n",
    "    return logits, labels\n",
    "\n",
    "def NT_loss(logits):\n",
    "    exp_logits = np.exp(logits)\n",
    "    sum_exp_logits = np.sum(exp_logits, axis=1)\n",
    "    \n",
    "    [n,m] = logits.shape\n",
    "    # print('sum_exp_logits='+str(sum_exp_logits.shape))\n",
    "    # print('exp_logits='+str(exp_logits.shape))\n",
    "    \n",
    "    L = []\n",
    "    for i in range(n):\n",
    "        l = []\n",
    "        for j in range(m):\n",
    "            aa = np.log(exp_logits[i,j]/sum_exp_logits[i])\n",
    "            # print(aa)\n",
    "            l.append(-np.log(exp_logits[i,j]/sum_exp_logits[i]))\n",
    "                    \n",
    "        L.append(l)\n",
    "    \n",
    "    L = np.array(L)\n",
    "    loss = 0\n",
    "    n_2 = int(n/2)\n",
    "    for i in range(n_2):\n",
    "        loss += (L[i,0]+L[i+n_2-1,0])/(2*n)\n",
    "    \n",
    "    print('NCE='+str(loss))\n",
    "    # loss = loss/n\n",
    "    return loss\n",
    "# # features = np.array([[1,2,3],[3,2,1]])/np.linalg.norm(a, axis=1, keepdims=True)\n",
    "# a = 0.1*np.random.rand(2*32,19, requires_grad=True)\n",
    "# # features = a/np.linalg.norm(a, axis=1, keepdims=True)\n",
    "# logits, labels = info_nce_loss(a,2,32)\n",
    "# print(logits.shape)\n",
    "# print(labels.shape)\n",
    "# # print(np.where(labels==1))\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # loss=criterion(logits, labels)\n",
    "# loss=NT_loss(logits)#, labels)\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b707b883-de37-4a0e-8b14-364eaca5d7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "    \n",
    "def distance_loss(predictions1, predictions2):\n",
    "    from sklearn.metrics import log_loss\n",
    "    [n,m] = predictions1.shape\n",
    "    # print('n={}'.format(n))\n",
    "    loss = 0\n",
    "    \n",
    "    entropy = 0\n",
    "    error = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            p = predictions1[i,:]\n",
    "            q = predictions2[j,:]\n",
    "            # print('(p-q)='+str((p-q).shape))\n",
    "            metric = torch.matmul((p-q).T,p-q)#l.Tog_loss(p,q)\n",
    "            # print('metric='+str(metric.shape))\n",
    "            # metric = np.linalg.norm((d1 - d2)) ** 2\n",
    "            if i==j:\n",
    "                entropy += metric\n",
    "            else:\n",
    "                entropy -= metric\n",
    "    entropy = entropy/n          \n",
    "    # error = np.linalg.norm((np.array(predictions1) - Y)) ** 2\n",
    "    loss = entropy# + error\n",
    "    \n",
    "    # loss = loss / len(labels)\n",
    "    # print(loss)\n",
    "    return loss  \n",
    "\n",
    "def cross_entropy(predictions1, predictions2):\n",
    "    [n,m] = predictions1.shape\n",
    "    \n",
    "    # sim = similarity(predictions1, predictions2)\n",
    "    loss = 0\n",
    "    entropy = 0\n",
    "    error = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            p = predictions1[i,:]\n",
    "            q = predictions2[j,:]\n",
    "            # print('p='+str(p))\n",
    "            part1 = np.max(np.dot( p, np.log(q) ), 0)\n",
    "            part2 = np.max(np.dot(1-p, np.log(1-q)), 0)\n",
    "            metric = part1 + part2\n",
    "            # print('metric='+str(metric))\n",
    "            # metric = np.linalg.norm((d1 - d2)) ** 2\n",
    "            if i==j:\n",
    "                entropy += metric\n",
    "            else:\n",
    "                entropy -= metric\n",
    "                \n",
    "    entropy = entropy/(n*n)          \n",
    "    # error = np.linalg.norm((np.array(predictions1) - Y)) ** 2\n",
    "    loss = entropy# + error\n",
    "    \n",
    "    # loss = loss / len(labels)\n",
    "    return loss    \n",
    "\n",
    "# def contrastive_loss(predictions1, predictions2):\n",
    "#     fusion = np.concatenate((predictions1, predictions2), axis=0)\n",
    "#     [n, m] = fusion.shape\n",
    "#     # print('fusion='+str(fusion.shape))\n",
    "#     logits, labels = info_nce_loss(np.array(fusion), 2, n/2)\n",
    "#     # criterion = torch.nn.CrossEntropyLoss()\n",
    "#     loss = NT_loss(logits)\n",
    "#     return loss    \n",
    "\n",
    "def Neumann_loss(predictions1, predictions2):\n",
    "    #n--sample  m--feature \n",
    "    [n,m] = predictions1.shape\n",
    "    ones = torch.ones([m,m])\n",
    "    # print('n={}'.format(n))\n",
    "    loss = 0\n",
    "    \n",
    "    entropy = 0#np.zeros([n,m])\n",
    "    error = 0\n",
    "    for i in range(n):\n",
    "        entropy_i = 0\n",
    "        for j in range(n):\n",
    "            p = predictions1[i,:].reshape(-1,1)\n",
    "            q = predictions2[j,:].reshape(-1,1)\n",
    "            d1 = torch.matmul(p, p.T)\n",
    "            # print('d1='+str(d1.shape))\n",
    "            d2 = torch.matmul(q, q.T)\n",
    "            # d2_pos = torch.maximum(ones-d2)\n",
    "            # sub_d2_pos = torch.maximum(ones-d2)\n",
    "            metric_1 = torch.trace(torch.matmul(d1, torch.log2(d2)))+torch.trace(torch.matmul(ones-d1, torch.log2(d2)))# + np.trace(np.dot(d2, np.log2(d2)))- np.trace(np.dot(d2, np.log2(d1))))/2\n",
    "            metric_2 = (torch.trace(torch.matmul(d2, torch.log2(d1)))+torch.trace(torch.matmul(ones-d2, torch.log2(ones-d1))))\n",
    "            metric = metric_1 + metric_2\n",
    "            \n",
    "            if i==j:\n",
    "                entropy += metric\n",
    "            else:\n",
    "                entropy -= metric\n",
    "                \n",
    "    entropy = entropy           \n",
    "    # error = np.linalg.norm((np.array(predictions1) - Y)) ** 2\n",
    "    \n",
    "    loss = entropy# + error\n",
    "    return loss\n",
    "\n",
    "def density_loss(predictions1, predictions2):\n",
    "    #n--sample  m--feature \n",
    "    [n,m] = predictions1.shape\n",
    "    ones = torch.ones([m,m])\n",
    "    # print('n={}'.format(n))\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            p = predictions1[i,:].reshape(-1,1)\n",
    "            q = predictions2[j,:].reshape(-1,1)\n",
    "            d1 = torch.sqrt(torch.matmul(p, p.T))\n",
    "            d2 = torch.sqrt(torch.matmul(q, q.T))\n",
    "            sim = torch.trace(torch.matmul(d1,d2))\n",
    "            \n",
    "            if i==j:\n",
    "                loss -= sim\n",
    "            if i!=j:\n",
    "                loss += sim  \n",
    "    # print('density_loss='+str(loss/n))\n",
    "    return loss/(n)\n",
    "\n",
    "def quantum_loss(predictions1, predictions2):\n",
    "    #n--sample  m--feature \n",
    "    [n,m] = predictions1.shape\n",
    "    ones = torch.ones([m,m])\n",
    "    # print('n={}'.format(n))\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        p1 = predictions1[i,:].reshape(-1,1)\n",
    "        p2 = predictions2[i,:].reshape(-1,1)\n",
    "        pho = 0.5*(torch.sqrt(torch.matmul(p1, p1.T))+torch.sqrt(torch.matmul(p2, p2.T)))\n",
    "        sigma = 0*pho\n",
    "        for j in range(n):\n",
    "            p = predictions1[i,:].reshape(-1,1)\n",
    "            q = predictions2[j,:].reshape(-1,1)\n",
    "            d1 = torch.matmul(p, p.T)\n",
    "            d2 = torch.matmul(q, q.T)\n",
    "            if i!=j:\n",
    "                sigma += (d1+d2)/(2*n-2)\n",
    "        diff = pho - sigma\n",
    "        loss += torch.trace(torch.matmul(diff.T, diff))/n \n",
    "    # print('quantum_loss='+str(loss))\n",
    "    return loss/(n*n)\n",
    "\n",
    "def quantumSSL_loss(predictions1, predictions2):\n",
    "    \n",
    "    # [2*B, D]\n",
    "    batch_size = predictions1.shape[0]\n",
    "    temperature = 0.07\n",
    "    out = torch.cat([predictions1, predictions2], dim=0)\n",
    "\n",
    "    # [2*B, 2*B]\n",
    "    sim_matrix = torch.exp(torch.mm(out, out.t().contiguous()) / temperature)\n",
    "    mask = (torch.ones_like(sim_matrix) - torch.eye(2 * batch_size)).type(torch.bool)\n",
    "    # [2*B, 2*B-1]\n",
    "    sim_matrix = sim_matrix.masked_select(mask).view(2 * batch_size, -1)\n",
    "    # compute loss\n",
    "    pos_sim = torch.exp(torch.sum(predictions1 * predictions2, dim=-1) / temperature)\n",
    "    # [2*B]\n",
    "    pos_sim = torch.cat([pos_sim, pos_sim], dim=0)\n",
    "\n",
    "    loss = (- torch.log(pos_sim / sim_matrix.sum(dim=-1))).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f68156ba-7d00-4f23-9b31-d2114c93709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, gammas, x):\n",
    "    pred = circuit(weights, gammas, x) \n",
    "    # print(pred)\n",
    "    return pred\n",
    "\n",
    "def semi_loss(predictions_FSL, predictions_CL1, predictions_CL2, Y_FSL, alpha):\n",
    "\n",
    "    cl_loss = distance_loss(predictions_CL1, predictions_CL2)\n",
    "    # print('cl_loss='+str(cl_loss))\n",
    "    diff = predictions_FSL - Y_FSL\n",
    "    # diff2 = predictions_CL2 - \n",
    "    \n",
    "    error = torch.trace(torch.matmul(diff.T, diff))#+np.trace(np.dot(diff2.T, diff2))\n",
    "    # print('cl_loss='+str(cl_loss)+' ,error='+str(error))\n",
    "    loss = alpha*cl_loss + (1-alpha) * error\n",
    "    return loss\n",
    "\n",
    "def cost(weights, alpha, gammas1, gammas2, X_batch, X_FSL, Y_FSL):\n",
    "    loss = 0\n",
    "    # gamma = 0.01\n",
    "    predictions_FSL = []\n",
    "    predictions_CL1 = []\n",
    "    predictions_CL2 = []\n",
    "    \n",
    "    for x in X_FSL:\n",
    "        predictions_FSL.append(variational_classifier(weights, 0.0*gammas1, x))\n",
    "        predictions_CL1.append(variational_classifier(weights, gammas1, x))\n",
    "        predictions_CL2.append(variational_classifier(weights, gammas2, x))\n",
    "    \n",
    "    for x in X_batch:\n",
    "        predictions_CL1.append(variational_classifier(weights, gammas1, x))\n",
    "        predictions_CL2.append(variational_classifier(weights, gammas2, x))\n",
    "    \n",
    "    loss = semi_loss(torch.stack(predictions_FSL), torch.stack(predictions_CL1), torch.stack(predictions_CL2), Y_FSL, alpha)\n",
    "    # print('loss='+str(loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b606df-af61-4d5c-bdee-44948a45c058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def linear_decision(features, labels):\n",
    "    # features = np.array(features)\n",
    "    model = svm.SVC()\n",
    "    model.fit(features, labels)\n",
    "    return model\n",
    "    \n",
    "def cluster(features):\n",
    "    kmeans = KMeans(n_clusters=3, random_state=0, n_init=\"auto\").fit(features)\n",
    "    pred = kmeans.labels_\n",
    "    return pred\n",
    "    \n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    count = 0\n",
    "    # print('predict='+str(predictions))\n",
    "    for l, p in zip(labels, predictions):\n",
    "        \n",
    "        # print(l)\n",
    "        l_class = torch.where(l==torch.max(l))[0]\n",
    "        p_class = torch.where(p==torch.max(p))[0]\n",
    "        # print('l_class='+str(l_class))\n",
    "        # print('p_class='+str(p_class))\n",
    "        # if abs(l_class - p_class) < 1e-5:\n",
    "        #     loss = loss + 1\n",
    "            # print('loss='+str(loss))\n",
    "        # print('[l,p]=[{},{}].'.format(l_class[0],p_class[0]))\n",
    "        if l_class[0] == p_class[0]:\n",
    "            count = count+1\n",
    "    acc = count / len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9af4756-ef92-425a-8095-78e0f9afc727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.loadtxt(\"./data/mnist_35_836.csv\", delimiter=',')\n",
    "# X = torch.tensor(data[:, 0:196], requires_grad=False)\n",
    "# X = torch.tensor(data[:, 32:32+2**(num_qubits-1)], requires_grad=False)\n",
    "X = torch.tensor(data[:, 0:196], requires_grad=False)\n",
    "X = X/255*(torch.pi)\n",
    "label = torch.tensor(data[:, -1], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc97501a-0f53-4f3c-9c33-ba9114d4cde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12345\n"
     ]
    }
   ],
   "source": [
    "seed = 12345\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "print(seed)        \n",
    "setup_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa4b303-3cd9-4cda-b424-fd358ef18e14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196])\n"
     ]
    }
   ],
   "source": [
    "from pennylane.optimize import NesterovMomentumOptimizer, AdamOptimizer\n",
    "\n",
    "num_layers = 2\n",
    "\n",
    "weights = torch.normal(mean=0.0, std=1, size=(num_layers,num_qubits,w_dim),requires_grad=True)#torch.randn(num_layers, num_qubits, w_dim, requires_grad=True)\n",
    "alpha = cl_loss_weight#np.array(cl_loss_weight)#, requires_grad=False)\n",
    "gammas1 =  torch.normal(mean=1.0, std=2, size=(X.shape[1],))\n",
    "gammas2 =  torch.normal(mean=0.0, std=1, size=(X.shape[1],))\n",
    "print(gammas1.shape)\n",
    "zeros = 0.0 * torch.randn(X.shape[1], requires_grad=False)#np.array(0.10, requires_grad=False)\n",
    "\n",
    "# opt = NesterovMomentumOptimizer(learning_rate)\n",
    "# opt = AdamOptimizer(learning_rate)\n",
    "# weights = weights.float()\n",
    "learning_rate = 5e-2\n",
    "opt = torch.optim.Adam([weights], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9de5c0ab-39ab-4b42-8d84-696d9e3f6347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133003/3360964317.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_train= torch.tensor(torch.zeros([class_binary_train.shape[0], 2]), requires_grad=False)\n",
      "/tmp/ipykernel_133003/3360964317.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_test= torch.tensor(torch.zeros([class_binary_test.shape[0], 2]), requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, label_train, label_test = train_test_split(X, label, test_size=0.25, random_state=seed)\n",
    "\n",
    "class0_index_train = torch.where(label_train==0)[0]\n",
    "class1_index_train = torch.where(label_train==1)[0]\n",
    "\n",
    "class_binary_train = torch.cat( (class0_index_train, class1_index_train), dim=0)\n",
    "\n",
    "shot = 5\n",
    "few_shot_index = torch.cat((class0_index_train[:shot], class1_index_train[:shot]), dim=0)\n",
    "# print(few_shot_index)\n",
    "\n",
    "Y_train= torch.tensor(torch.zeros([class_binary_train.shape[0], 2]), requires_grad=False)\n",
    "for i in range(class_binary_train.shape[0]):\n",
    "    Y_train[i, int(label_train[i])]=1   \n",
    "\n",
    "batch_size = 10\n",
    "batch_index = torch.randint(0, len(X_train), (batch_size,))\n",
    "    \n",
    "class0_index_test = torch.where(label_test==0)[0]\n",
    "class1_index_test = torch.where(label_test==1)[0]\n",
    "\n",
    "class_binary_test = torch.cat( (class0_index_test, class1_index_test), dim=0)\n",
    "Y_test= torch.tensor(torch.zeros([class_binary_test.shape[0], 2]), requires_grad=False)\n",
    "for i in range(class_binary_test.shape[0]):\n",
    "    Y_test[i, int(label_test[i])]=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f354bd29-3f3f-4641-8611-3f3fdc0097fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "acc_svm=0.6555023923444976\n",
      "acc_nnc=0.6842105263157895\n",
      "acc_knn=0.6411483253588517\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# print('start')\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Update the weights by one optimizer step\u001b[39;00m\n\u001b[1;32m     45\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 46\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgammas1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgammas2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_FSL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_FSL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     48\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m, in \u001b[0;36mcost\u001b[0;34m(weights, alpha, gammas1, gammas2, X_batch, X_FSL, Y_FSL)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_FSL:\n\u001b[1;32m     26\u001b[0m     predictions_FSL\u001b[38;5;241m.\u001b[39mappend(variational_classifier(weights, \u001b[38;5;241m0.0\u001b[39m\u001b[38;5;241m*\u001b[39mgammas1, x))\n\u001b[0;32m---> 27\u001b[0m     predictions_CL1\u001b[38;5;241m.\u001b[39mappend(\u001b[43mvariational_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgammas1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     28\u001b[0m     predictions_CL2\u001b[38;5;241m.\u001b[39mappend(variational_classifier(weights, gammas2, x))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_batch:\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36mvariational_classifier\u001b[0;34m(weights, gammas, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvariational_classifier\u001b[39m(weights, gammas, x):\n\u001b[0;32m----> 2\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mcircuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgammas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# print(pred)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m~/anaconda3/envs/QSSL/lib/python3.9/site-packages/pennylane/qnode.py:853\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m         set_shots(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_device, override_shots)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_gradient_fn)()\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# construct the tape\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    856\u001b[0m using_custom_cache \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__setitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__delitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    860\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/QSSL/lib/python3.9/site-packages/pennylane/qnode.py:757\u001b[0m, in \u001b[0;36mQNode.construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m old_interface \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_interface(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m--> 757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape \u001b[38;5;241m=\u001b[39m \u001b[43mmake_qscript\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39m_qfunc_output\n\u001b[1;32m    760\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/QSSL/lib/python3.9/site-packages/pennylane/tape/qscript.py:1378\u001b[0m, in \u001b[0;36mmake_qscript.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m AnnotatedQueue() \u001b[38;5;28;01mas\u001b[39;00m q:\n\u001b[0;32m-> 1378\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1380\u001b[0m     qscript \u001b[38;5;241m=\u001b[39m QuantumScript\u001b[38;5;241m.\u001b[39mfrom_queue(q)\n\u001b[1;32m   1381\u001b[0m     qscript\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m result\n",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m, in \u001b[0;36mcircuit\u001b[0;34m(weights, gammas, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@qml\u001b[39m\u001b[38;5;241m.\u001b[39mqnode(dev, interface\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;66;03m#, diff_method=\"backprop\")#interface=\"autograd\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcircuit\u001b[39m(weights, gammas, x):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m num_qubits, layer_type\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mFRQI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_qubits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgammas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# qml.BasicEntanglerLayers(weights[:,0], wires=range(num_qubits))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m W \u001b[38;5;129;01min\u001b[39;00m weights:\n",
      "Cell \u001b[0;32mIn[1], line 79\u001b[0m, in \u001b[0;36mFRQI\u001b[0;34m(input_data, num_qubits, gammas)\u001b[0m\n\u001b[1;32m     76\u001b[0m     qml\u001b[38;5;241m.\u001b[39mHadamard(i)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(input_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 79\u001b[0m     \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctrl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation_wires\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation_strings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_wire\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     qml\u001b[38;5;241m.\u001b[39mctrl(qml\u001b[38;5;241m.\u001b[39mRZ, control\u001b[38;5;241m=\u001b[39mlocation_wires, control_values\u001b[38;5;241m=\u001b[39mlocation_strings[i])(gammas[i], target_wire)\n",
      "File \u001b[0;32m~/anaconda3/envs/QSSL/lib/python3.9/site-packages/pennylane/ops/op_math/controlled.py:112\u001b[0m, in \u001b[0;36mctrl.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_control_on_zero:\n\u001b[1;32m    110\u001b[0m     _ \u001b[38;5;241m=\u001b[39m [qml\u001b[38;5;241m.\u001b[39mPauliX(w) \u001b[38;5;28;01mfor\u001b[39;00m w, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(control, control_values) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m val]\n\u001b[0;32m--> 112\u001b[0m _ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    113\u001b[0m     Controlled(\n\u001b[1;32m    114\u001b[0m         op, control_wires\u001b[38;5;241m=\u001b[39mcontrol, control_values\u001b[38;5;241m=\u001b[39mop_control_values, work_wires\u001b[38;5;241m=\u001b[39mwork_wires\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m qscript\u001b[38;5;241m.\u001b[39moperations\n\u001b[1;32m    117\u001b[0m ]\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_control_on_zero:\n\u001b[1;32m    120\u001b[0m     _ \u001b[38;5;241m=\u001b[39m [qml\u001b[38;5;241m.\u001b[39mPauliX(w) \u001b[38;5;28;01mfor\u001b[39;00m w, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(control, control_values) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m val]\n",
      "File \u001b[0;32m~/anaconda3/envs/QSSL/lib/python3.9/site-packages/pennylane/ops/op_math/controlled.py:113\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_control_on_zero:\n\u001b[1;32m    110\u001b[0m     _ \u001b[38;5;241m=\u001b[39m [qml\u001b[38;5;241m.\u001b[39mPauliX(w) \u001b[38;5;28;01mfor\u001b[39;00m w, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(control, control_values) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m val]\n\u001b[1;32m    112\u001b[0m _ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 113\u001b[0m     \u001b[43mControlled\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_wires\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_control_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork_wires\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwork_wires\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m qscript\u001b[38;5;241m.\u001b[39moperations\n\u001b[1;32m    117\u001b[0m ]\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_control_on_zero:\n\u001b[1;32m    120\u001b[0m     _ \u001b[38;5;241m=\u001b[39m [qml\u001b[38;5;241m.\u001b[39mPauliX(w) \u001b[38;5;28;01mfor\u001b[39;00m w, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(control, control_values) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m val]\n",
      "File \u001b[0;32m~/anaconda3/envs/QSSL/lib/python3.9/site-packages/pennylane/ops/op_math/controlled.py:611\u001b[0m, in \u001b[0;36mControlledOp.__init__\u001b[0;34m(self, base, control_wires, control_values, work_wires, do_queue, id)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28mself\u001b[39m, base, control_wires, control_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, work_wires\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, do_queue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    610\u001b[0m ):\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_wires\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork_wires\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;66;03m# check the grad_recipe validity\u001b[39;00m\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_recipe \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m         \u001b[38;5;66;03m# Make sure grad_recipe is an iterable of correct length instead of None\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/QSSL/lib/python3.9/site-packages/pennylane/ops/op_math/controlled.py:263\u001b[0m, in \u001b[0;36mControlled.__init__\u001b[0;34m(self, base, control_wires, control_values, work_wires, do_queue, id)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# All values not 0 are cast as true. Assumes a string of 1s and 0s.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     control_values \u001b[38;5;241m=\u001b[39m [(x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m control_values]\n\u001b[1;32m    260\u001b[0m control_values \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    261\u001b[0m     [\u001b[38;5;28mbool\u001b[39m(control_values)]\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(control_values, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mbool\u001b[39m(control_value) \u001b[38;5;28;01mfor\u001b[39;00m control_value \u001b[38;5;129;01min\u001b[39;00m control_values]\n\u001b[1;32m    264\u001b[0m )\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(control_values) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(control_wires):\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontrol_values should be the same length as control_wires\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/QSSL/lib/python3.9/site-packages/pennylane/ops/op_math/controlled.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# All values not 0 are cast as true. Assumes a string of 1s and 0s.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     control_values \u001b[38;5;241m=\u001b[39m [(x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m control_values]\n\u001b[1;32m    260\u001b[0m control_values \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    261\u001b[0m     [\u001b[38;5;28mbool\u001b[39m(control_values)]\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(control_values, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mbool\u001b[39m(control_value) \u001b[38;5;28;01mfor\u001b[39;00m control_value \u001b[38;5;129;01min\u001b[39;00m control_values]\n\u001b[1;32m    264\u001b[0m )\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(control_values) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(control_wires):\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontrol_values should be the same length as control_wires\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/QSSL/lib/python3.9/site-packages/pennylane/numpy/tensor.py:190\u001b[0m, in \u001b[0;36mtensor.__getitem__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, tensor):\n\u001b[0;32m--> 190\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m item\n",
      "File \u001b[0;32m~/anaconda3/envs/QSSL/lib/python3.9/site-packages/pennylane/numpy/tensor.py:113\u001b[0m, in \u001b[0;36mtensor.__new__\u001b[0;34m(cls, input_array, requires_grad, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, input_array, \u001b[38;5;241m*\u001b[39margs, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    111\u001b[0m     obj \u001b[38;5;241m=\u001b[39m asarray(input_array, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[43monp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m):\n\u001b[1;32m    114\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    115\u001b[0m         obj\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m requires_grad\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "\n",
    "costs = []\n",
    "accs = []\n",
    "\n",
    "X_FSL = X_train[few_shot_index]\n",
    "label_FSL = label_train[few_shot_index]\n",
    "Y_FSL = Y_train[few_shot_index]\n",
    "\n",
    "print(label_FSL)\n",
    "model = linear_decision(X_FSL, label_FSL)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "acc_svm = accuracy_score(pred, label_test)\n",
    "print('acc_svm='+str(acc_svm))\n",
    "\n",
    "model = NearestCentroid()\n",
    "model.fit(X_FSL, label_FSL)\n",
    "pred = model.predict(X_test)\n",
    "acc_nnc = accuracy_score(pred, label_test)\n",
    "print('acc_nnc='+str(acc_nnc))\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_FSL, label_FSL)\n",
    "pred = model.predict(X_test)\n",
    "acc_knn = accuracy_score(pred, label_test)\n",
    "print('acc_knn='+str(acc_knn))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for it in range(100):\n",
    "    # # np.random.seed(42)\n",
    "    # if it%10==0:\n",
    "    #     batch_index = torch.randint(0, len(X), (batch_size,))\n",
    "    iter_start = time.time()\n",
    "    X_batch = X_train[batch_index]\n",
    "    label_batch = label_train[batch_index]\n",
    "    # print('start')\n",
    "    # Update the weights by one optimizer step\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss = cost(weights, alpha, gammas1, gammas2, X_batch, X_FSL, Y_FSL)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    # print(opt.step(cost, weights, gamma, X_batch, Y_batch)\n",
    "    # weights, _, _, _, _, _, _ = opt.step(cost, weights, alpha, gammas1, gammas2, X_batch, X_FSL, Y_FSL)\n",
    "    \n",
    "    step_end = time.time()\n",
    "    # print('time_step='+str(step_end-start))\n",
    "    \n",
    "    # Compute accuracy\n",
    "    res = torch.stack([variational_classifier(weights, zeros, x) for x in X_test])\n",
    "\n",
    "    acc = accuracy(res, Y_test)    \n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, loss, acc\n",
    "        )\n",
    "    )\n",
    "    accs.append(acc)\n",
    "    costs.append(loss.detach().numpy())\n",
    "    iter_end = time.time()\n",
    "    print('iter_time='+str(iter_end-iter_start))\n",
    "    \n",
    "all_end = time.time()\n",
    "print('epoch_time='+str(all_end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243d750-dbc4-4705-832d-7112968cbcc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.clf()\n",
    "print(len(accs))\n",
    "x= [i for i in range(len(accs))]\n",
    "plt.figure(1)\n",
    "\n",
    "plt.plot(x, accs[:])\n",
    "%matplotlib inline\n",
    "# plt.show()\n",
    "file_paras = str(layer_type)+' r-'+str(learning_rate)+' layer-'+str(num_layers)+' shot-'+str(shot)+' num_qubits-'+str(num_qubits)+' alpha-'+str(alpha)\n",
    "plt.savefig(file_paras+' distance_loss few_acc.jpg')\n",
    "print(max(accs))\n",
    "np.savetxt(file_paras+' distance_loss few_acc.txt',accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ae9e0-54b8-45be-8da1-909b052357a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.clf()\n",
    "print(len(costs))\n",
    "x= [i for i in range(len(costs))]\n",
    "plt.figure(1)\n",
    "\n",
    "plt.plot(x, costs[:])\n",
    "%matplotlib inline\n",
    "# plt.show()\n",
    "file_paras = str(layer_type)+' r-'+str(learning_rate)+' layer-'+str(num_layers)+' shot-'+str(shot)+' num_qubits-'+str(num_qubits)+' alpha-'+str(alpha)\n",
    "plt.savefig(file_paras+' distance_loss few_loss.jpg')\n",
    "print(max(accs))\n",
    "np.savetxt(file_paras+' distance_loss few_loss.txt',costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c51c9-8717-480e-8161-04d54be57256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit_expval(theta):\n",
    "    qml.RX(theta, wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    return qml.expval(qml.PauliY(0))\n",
    "\n",
    "circuit_expval(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fa629c-44ae-40b3-89e7-007d92d16fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit_var(theta):\n",
    "    qml.RX(theta, wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    return qml.var(qml.PauliY(0))\n",
    "\n",
    "circuit_var(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf1045-f988-42ae-9924-e9e23793cfa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=2, shots=4)\n",
    "@qml.qnode(dev)\n",
    "def circuit_sample(theta):\n",
    "    qml.RX(theta, wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    return qml.sample(qml.PauliY(0))\n",
    "\n",
    "circuit_sample(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e1f33-72d9-48d4-a1ef-83abb375d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b1dc3-c4e7-4075-979d-96d0e0eca5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QSSL",
   "language": "python",
   "name": "qssl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
