{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d990d3-cb59-4d4c-b905-17328c02e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "sys.path.append('/your_path/QAIL')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from layer.GENERAL_RAM import GENERAL_RAM\n",
    "\n",
    "from utils.info import *\n",
    "\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from easyfsl.utils import plot_images, sliding_average\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from itertools import product\n",
    "from utils.dataManager import *\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage import io\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5082e9-77cc-4b9e-8dc1-f253bb51604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = set_params()\n",
    "\n",
    "args = parser.parse_args(args=['--model', 'GENERAL_RAM',\n",
    "                               '--seed','500',\n",
    "                               '--strategy','ALL',\n",
    "                               '--data','FashionMNIST',                    \n",
    "                               '--N_WAY','4',\n",
    "                               '--N_TRAIN','100',\n",
    "                               '--N_VALIDATE','20',\n",
    "                               '--N_TEST','100',\n",
    "                               '--N_SHOT','30',\n",
    "                               '--N_ACTIVE','2',\n",
    "                               '--N_ACTIVE_TIMES','30',\n",
    "                               '--classes','0','1','2','3',\n",
    "                               '--num_layers','4',\n",
    "                               '--num_qubits','8',\n",
    "                               '--learning_rate','1e-1'])\n",
    "\n",
    "print(args)\n",
    "\n",
    "setup_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f04d8-026b-494a-be1f-983a746ab3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff2e01-e3fb-4e9c-9188-9c274dc5c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = sample_data_qac(args)\n",
    "\n",
    "images_train = torch.cat([data.reshape(1,-1) for data in images['train']], dim=0)\n",
    "images_valid = torch.cat([data.reshape(1,-1) for data in images['validate']], dim=0)\n",
    "images_test = torch.cat([data.reshape(1,-1) for data in images['test']], dim=0)\n",
    "\n",
    "labels_train = torch.stack(labels['train'])\n",
    "labels_valid = torch.stack(labels['validate'])\n",
    "labels_test = torch.stack(labels['test'])\n",
    "\n",
    "plot_images(images['train'], \"query images\", images_per_row=args.N_TRAIN)\n",
    "\n",
    "print(images_train.shape)\n",
    "print(images_valid.shape)\n",
    "print(images_test.shape)\n",
    "    \n",
    "\n",
    "X_train = torch.tensor(normalize(torch.tensor(images_train.view(args.N_TRAIN*args.N_WAY, -1), requires_grad=False),norm='l2'))\n",
    "label_train = torch.tensor(labels_train, requires_grad=False)\n",
    "Y_train= torch.tensor(torch.zeros([label_train.shape[0], args.N_WAY]), requires_grad=False)\n",
    "for i in range(label_train.shape[0]):\n",
    "    Y_train[i, int(label_train[i])]=1  \n",
    "    \n",
    "X_test =  torch.tensor(normalize(torch.tensor(images_test.view(args.N_TEST*args.N_WAY, -1), requires_grad=False),norm='l2'))\n",
    "label_test = torch.tensor(labels_test, requires_grad=False)\n",
    "Y_test= torch.tensor(torch.zeros([label_test.shape[0], args.N_WAY]), requires_grad=False)\n",
    "for i in range(label_test.shape[0]):\n",
    "    Y_test[i, int(label_test[i])]=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d141f-8bdf-4dfd-a3d6-308dded5868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, img_as_float\n",
    "\n",
    "def SSIM_compute(images, args):\n",
    "    N = len(images['train'])\n",
    "    \n",
    "    mat = torch.Tensor(N,N)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            img1 = img_as_float(images['train'][i]).reshape(args.N_SIZE,args.N_SIZE)\n",
    "            img2 = img_as_float(images['train'][j]).reshape(args.N_SIZE,args.N_SIZE)\n",
    "            ssim_value, _ = ssim(img1, img2, multichannel=False, full=True)\n",
    "            mat[i, j] = ssim_value.item()\n",
    "    \n",
    "    return mat\n",
    "\n",
    "AdjMtx = SSIM_compute(images, args)\n",
    "topo_list = torch.sum(AdjMtx > 0.7, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcafa7db-bfe0-434d-8cd2-c5bbc9e2e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_loss(predictions_FSL, Y_FSL):\n",
    "    diff = predictions_FSL - Y_FSL\n",
    "    error = torch.trace(torch.matmul(diff.T, diff))\n",
    "    return error\n",
    "\n",
    "def semi_loss_qcnn(predictions_FSL, predictions_CL1, predictions_CL2, Y_FSL, alpha):\n",
    "    contrative_loss = CLoss_select('Distance')(predictions_CL1, predictions_CL2)\n",
    "    diff = 1.0 - torch.sum(predictions_FSL[:, 0]==YSL)/ Y_FSL.shape[0]\n",
    "    error = torch.trace(torch.matmul(diff.T, diff))\n",
    "    loss = alpha*contrative_loss + (1-alpha) * error\n",
    "    return loss\n",
    "\n",
    "def cost(qnet, weights, X_FSL_FRQI, Y_FSL):\n",
    "    loss = 0\n",
    "    pred = qnet(weights, X_FSL_FRQI)\n",
    "    loss = semi_loss(qnet(weights, X_FSL_FRQI), Y_FSL)\n",
    "    return qnet(weights, X_FSL_FRQI), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e0779-fe46-46a8-b855-7716b42cc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = 0.0 * torch.randn(X_train.shape[1], requires_grad=False)\n",
    "\n",
    "if args.model=='GENERAL_RAM':\n",
    "    weights_init = torch.normal(mean=0.0, std=1, size=(args.num_layers,args.num_qubits,3),requires_grad=True)\n",
    "    quantum_neural_network = GENERAL_RAM(args.num_qubits)\n",
    "    \n",
    "X_train_state = []\n",
    "X_test_state = []\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train_state.append(quantum_neural_network.qnode_amplitude(X_train[i,:], zeros))\n",
    "\n",
    "X_train_state = torch.stack(X_train_state)\n",
    "\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_state.append(quantum_neural_network.qnode_amplitude(X_test[i,:], zeros))\n",
    "    \n",
    "X_test_state = torch.stack(X_test_state)\n",
    "images_fsl, labels_fsl, state_fsl, y_fsl, images_query, labels_query, state_query, y_query, AdjMtx = split_fsl_query_random(X_train_state, Y_train, images_train, labels_train, AdjMtx, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233dd66c-e505-429f-a93b-6bf72548f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score\n",
    "import time\n",
    "import numpy as np\n",
    "import threading\n",
    "    \n",
    "def active_learning(weights_init, args, quantum_neural_network, state_fsl, y_fsl, state_query, y_query, X_test_state, Y_test, AdjMtx):\n",
    "    logger = get_logger(str(args.strategy)+'_'+str(args.data) + '_' + str(args.data_method) + '_' + str(args.N_SHOT) + '_' + str(args.num_layers) + '.log')\n",
    "    accs = []\n",
    "    weight_history = []\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    weight_history.append(weights_init)\n",
    "    \n",
    "    for it_ac in range(args.N_ACTIVE_TIMES+1):\n",
    "        iter_start_ac = time.time()\n",
    "        weights = weights_init\n",
    "        opt = torch.optim.Adam([weights], lr = args.learning_rate)\n",
    "        for it in range(100):\n",
    "            iter_start = time.time()\n",
    "\n",
    "            opt.zero_grad()\n",
    "            train_res, loss = cost(quantum_neural_network.qnode_qnn, weights, state_fsl, y_fsl)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            train_acc = accuracy(train_res, y_fsl)\n",
    "\n",
    "        \n",
    "        state_fsl, y_fsl, state_query, y_query, AdjMtx = add_sample(quantum_neural_network, weights, state_fsl, y_fsl, state_query, y_query, AdjMtx, args)\n",
    "        \n",
    "        res = quantum_neural_network.qnode_qnn(weights, X_test_state) \n",
    "        test_acc = accuracy(res, Y_test)\n",
    "        \n",
    "        iter_end_ac = time.time()\n",
    "        logger.info('{}\\t Epoch_AC:[{}/{}]\\t TRAIN ACCURACY={:.6f}\\t  TEST ACCURACY={:.6f} \\t time={:.3f}'.format(args.strategy, it_ac, args.N_ACTIVE_TIMES, train_acc, test_acc, iter_end_ac-iter_start_ac))\n",
    "        \n",
    "        print(torch.sum(y_fsl, dim=0))\n",
    "        accs.append(test_acc)\n",
    "        weight_history.append(weights)\n",
    "\n",
    "    all_end = time.time()\n",
    "    print('epoch_time='+str(all_end-start))\n",
    "    \n",
    "    print(state_fsl.shape)\n",
    "    print(y_fsl.shape)\n",
    "    print(state_query.shape)\n",
    "    print(y_query.shape)\n",
    "    \n",
    "    return accs, weight_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea9ebe-ce88-44b7-bdf2-bf5d6daee427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import copy\n",
    "\n",
    "args_rand = copy.deepcopy(args)\n",
    "args_rand.strategy = 'RAND'\n",
    "accs_rand, weight_history_rand = active_learning(weights_init, args_rand, quantum_neural_network, state_fsl, y_fsl, state_query, y_query, X_test_state, Y_test, AdjMtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c5ab3-b19a-41ea-a1bb-550b0513c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_entro = copy.deepcopy(args)\n",
    "args_entro.strategy = 'ENTRO'\n",
    "accs_entro, weight_history_entro = active_learning(weights_init, args_entro, quantum_neural_network, state_fsl, y_fsl, state_query, y_query, X_test_state, Y_test, AdjMtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d15d40-0704-4077-931b-b674c4540024",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_quantum = copy.deepcopy(args)\n",
    "args_quantum.strategy = 'QUANTUM'\n",
    "accs_quantum, weight_history_quantum = active_learning(weights_init, args_quantum, quantum_neural_network, state_fsl, y_fsl, state_query, y_query, X_test_state, Y_test, AdjMtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff698f-7256-426c-afaf-c2141a0faaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "nums = np.array([it for it in range(args.N_ACTIVE_TIMES+1)] )\n",
    "y_quantum = accs_quantum\n",
    "y_entro = accs_entro\n",
    "y_rand = accs_rand\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "line1 = ax.plot(nums, y_quantum, marker='o', linestyle='-', color='red', markersize=2, linewidth=2, label='QUANTUM')\n",
    "line2 = ax.plot(nums, y_entro, marker='x', linestyle='--', color='blue', markersize=2, linewidth=2, label='ENTROPY')\n",
    "line3 = ax.plot(nums, y_rand, marker='s', linestyle=':', color='green', markersize=2, linewidth=2, label='RANDOM')\n",
    "\n",
    "\n",
    "ax.set_ylabel('Classification ACC ($\\%$)', fontsize=16)\n",
    "ax.set_xlabel('Active learning rounds', fontsize=16)\n",
    "ax.set_title(args.data)\n",
    "\n",
    "ax.set_ylim([0.5, 0.97])\n",
    "\n",
    "legend = ax.legend()\n",
    "\n",
    "plt.savefig(r'../Figure/QIAL_'+'all_'+str(args.N_ACTIVE)+'-'+str(args.seed)+'-'+str(args.num_layers)+'.pdf', format='pdf', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f86f19c-8b37-438d-a7cf-b5e134e9771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "variables = {\n",
    "    'weight_history_quantum': weight_history_quantum,\n",
    "    'weight_history_entro': weight_history_entro,\n",
    "    'weight_history_rand': weight_history_rand,\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'X_train_state': X_train_state,\n",
    "    'X_test_state': X_test_state,\n",
    "    'Y_train': Y_train,\n",
    "    'Y_test': Y_test,\n",
    "    'accs_quantum': accs_quantum,\n",
    "    'accs_entro': accs_entro,\n",
    "    'accs_rand': accs_rand,\n",
    "    'args':args\n",
    "} \n",
    "\n",
    "file_path = (\n",
    "    '../results/' + args.data + '/' +\n",
    "    args.data + '_all' + '_'+str(args.seed)+'.pkl'\n",
    ")\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(variables, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quantum",
   "language": "python",
   "name": "quantum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
