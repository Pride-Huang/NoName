{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d990d3-cb59-4d4c-b905-17328c02e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "sys.path.append('/your_path/QIAL')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from layer.GENERAL_RAM import GENERAL_RAM\n",
    "from layer.MCNN3x2_RAM import MCNN3x2_RAM\n",
    "\n",
    "from utils.info import *\n",
    "\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from easyfsl.utils import plot_images, sliding_average\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from itertools import product\n",
    "from utils.dataManager import *\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage import io\n",
    "\n",
    "import warnings\n",
    "\n",
    "import copy\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5082e9-77cc-4b9e-8dc1-f253bb51604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = set_params()\n",
    "\n",
    "args = parser.parse_args(args=['--model', 'GENERAL_RAM',\n",
    "                               '--seed','500',\n",
    "                               '--strategy','ALL',\n",
    "                               '--data','FashionMNIST',                    \n",
    "                               '--N_WAY','4',\n",
    "                               '--N_TRAIN','100',\n",
    "                               '--N_VALIDATE','20',\n",
    "                               '--N_TEST','100',\n",
    "                               '--N_SHOT','30',\n",
    "                               '--N_ACTIVE','30',\n",
    "                               '--N_ACTIVE_TIMES','0',\n",
    "                               '--classes','0','1','2','3',\n",
    "                               '--num_layers','4',\n",
    "                               '--num_qubits','8',\n",
    "                               '--learning_rate','1e-1'])\n",
    "\n",
    "setup_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff2e01-e3fb-4e9c-9188-9c274dc5c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = sample_data_qac(args)\n",
    "\n",
    "images_train = torch.cat([data.reshape(1,-1) for data in images['train']], dim=0)\n",
    "images_valid = torch.cat([data.reshape(1,-1) for data in images['validate']], dim=0)\n",
    "images_test = torch.cat([data.reshape(1,-1) for data in images['test']], dim=0)\n",
    "\n",
    "labels_train = torch.stack(labels['train'])\n",
    "labels_valid = torch.stack(labels['validate'])\n",
    "labels_test = torch.stack(labels['test'])\n",
    "\n",
    "plot_images(images['train'], \"query images\", images_per_row=args.N_TRAIN)\n",
    "\n",
    "print(images_train.shape)\n",
    "print(images_valid.shape)\n",
    "print(images_test.shape)\n",
    "    \n",
    "\n",
    "X_train = torch.tensor(normalize(torch.tensor(images_train.view(args.N_TRAIN*args.N_WAY, -1), requires_grad=False),norm='l2'))\n",
    "label_train = torch.tensor(labels_train, requires_grad=False)\n",
    "Y_train= torch.tensor(torch.zeros([label_train.shape[0], args.N_WAY]), requires_grad=False)\n",
    "for i in range(label_train.shape[0]):\n",
    "    Y_train[i, int(label_train[i])]=1  \n",
    "    \n",
    "X_valid =  torch.tensor(normalize(torch.tensor(images_valid.view(args.N_VALIDATE*args.N_WAY, -1), requires_grad=False),norm='l2'))\n",
    "label_valid = torch.tensor(labels_valid, requires_grad=False)\n",
    "Y_valid= torch.tensor(torch.zeros([label_valid.shape[0], args.N_WAY]), requires_grad=False)\n",
    "for i in range(label_valid.shape[0]):\n",
    "    Y_valid[i, int(label_valid[i])]=1 \n",
    "\n",
    "X_test =  torch.tensor(normalize(torch.tensor(images_test.view(args.N_TEST*args.N_WAY, -1), requires_grad=False),norm='l2'))\n",
    "label_test = torch.tensor(labels_test, requires_grad=False)\n",
    "Y_test= torch.tensor(torch.zeros([label_test.shape[0], args.N_WAY]), requires_grad=False)\n",
    "for i in range(label_test.shape[0]):\n",
    "    Y_test[i, int(label_test[i])]=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d141f-8bdf-4dfd-a3d6-308dded5868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, img_as_float\n",
    "\n",
    "def SSIM_compute(images, args):\n",
    "    N = len(images['train'])\n",
    "    \n",
    "    mat = torch.Tensor(N,N)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            img1 = img_as_float(images['train'][i]).reshape(args.N_SIZE,args.N_SIZE)\n",
    "            img2 = img_as_float(images['train'][j]).reshape(args.N_SIZE,args.N_SIZE)\n",
    "            ssim_value, _ = ssim(img1, img2, multichannel=False, full=True)\n",
    "            mat[i, j] = ssim_value.item()\n",
    "    \n",
    "    return mat\n",
    "\n",
    "AdjMtx = SSIM_compute(images, args)\n",
    "topo_list = torch.sum(AdjMtx > 0.7, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcafa7db-bfe0-434d-8cd2-c5bbc9e2e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_loss(predictions_FSL, Y_FSL):\n",
    "    diff = predictions_FSL - Y_FSL\n",
    "    error = torch.trace(torch.matmul(diff.T, diff))\n",
    "    return error\n",
    "\n",
    "def semi_loss_qcnn(predictions_FSL, predictions_CL1, predictions_CL2, Y_FSL, alpha):\n",
    "    contrative_loss = CLoss_select('Distance')(predictions_CL1, predictions_CL2)\n",
    "    diff = 1.0 - torch.sum(predictions_FSL[:, 0]==YSL)/ Y_FSL.shape[0]\n",
    "    error = torch.trace(torch.matmul(diff.T, diff))\n",
    "    loss = alpha*contrative_loss + (1-alpha) * error\n",
    "    return loss\n",
    "\n",
    "def cost(qnet, weights, X_FSL_FRQI, Y_FSL):\n",
    "    pred = qnet(weights, X_FSL_FRQI)\n",
    "    loss = semi_loss(qnet(weights, X_FSL_FRQI), Y_FSL)\n",
    "    return qnet(weights, X_FSL_FRQI), loss\n",
    "\n",
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score\n",
    "import numpy as np\n",
    "import threading\n",
    "    \n",
    "def active_learning(weights_init, args, quantum_neural_network, state_fsl, y_fsl, state_query, y_query, X_test_state, Y_test, AdjMtx):\n",
    "    logger = get_logger(str(args.strategy)+'_'+str(args.data) + '_' + str(args.data_method) + '_' + str(args.N_SHOT) + '_' + str(args.num_layers) + '.log')\n",
    "    accs = []\n",
    "    weight_history = []\n",
    "\n",
    "    weight_history.append(weights_init)\n",
    "    for it_ac in range(args.N_ACTIVE_TIMES+1):\n",
    "        weights = weights_init\n",
    "        opt = torch.optim.Adam([weights], lr = args.learning_rate)\n",
    "        for it in range(100):\n",
    "            opt.zero_grad()\n",
    "            train_res, loss = cost(quantum_neural_network.qnode_qnn, weights, state_fsl, y_fsl)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_acc = accuracy(train_res, y_fsl)\n",
    "\n",
    "        args.strategy = 'ENTRO'\n",
    "        state_fsl_, y_fsl_, state_query_, y_query_, AdjMtx_, shannon_entropy = return_entropy(quantum_neural_network, weights, state_fsl, y_fsl, state_query, y_query, AdjMtx, args)\n",
    "        args.strategy = 'QUANTUM'\n",
    "        state_fsl_, y_fsl_, state_query_, y_query_, AdjMtx_, von_entropy = return_entropy(quantum_neural_network, weights, state_fsl, y_fsl, state_query, y_query, AdjMtx, args)        \n",
    "\n",
    "        res = quantum_neural_network.qnode_qnn(weights, X_test_state) \n",
    "        test_acc = accuracy(res, Y_test)\n",
    "        \n",
    "        logger.info('{}\\t Epoch_AC:[{}/{}]\\t TRAIN ACCURACY={:.6f}\\t  TEST ACCURACY={:.6f}'.format(args.strategy, it_ac, args.N_ACTIVE_TIMES, train_acc, test_acc))\n",
    "        \n",
    "        accs.append(test_acc)\n",
    "        weight_history.append(weights)\n",
    "\n",
    "    return accs, weight_history, shannon_entropy, von_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e0779-fe46-46a8-b855-7716b42cc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = 0.0 * torch.randn(X_train.shape[1], requires_grad=False)\n",
    "\n",
    "if args.model=='GENERAL_RAM':\n",
    "    weights_init = torch.normal(mean=0.0, std=1, size=(args.num_layers,args.num_qubits,3),requires_grad=True)\n",
    "    quantum_neural_network = GENERAL_RAM(args.num_qubits)\n",
    "    \n",
    "X_train_state = []\n",
    "X_test_state = []\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train_state.append(quantum_neural_network.qnode_amplitude(X_train[i,:], zeros))\n",
    "\n",
    "X_train_state = torch.stack(X_train_state)\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_state.append(quantum_neural_network.qnode_amplitude(X_test[i,:], zeros))\n",
    "    \n",
    "X_test_state = torch.stack(X_test_state)\n",
    "images_fsl, labels_fsl, state_fsl, y_fsl, images_query, labels_query, state_query, y_query, AdjMtx_ = split_fsl_query_random(X_train_state, Y_train, images_train, labels_train, AdjMtx, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d15d40-0704-4077-931b-b674c4540024",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_quantum = copy.deepcopy(args)\n",
    "args.strategy = 'QUANTUM'\n",
    "accs_quantum, weight_history_quantum,shannon_entropy, von_entropy = active_learning(weights_init, args_quantum, quantum_neural_network, state_fsl, y_fsl, state_query, y_query, X_test_state, Y_test, AdjMtx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36842b8-f34b-4731-881b-806434365451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "shannon_entropy_np = shannon_entropy.numpy()[:100]\n",
    "von_entropy_np = von_entropy.detach().numpy()[:100]\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "index = np.arange(len(shannon_entropy_np))\n",
    "\n",
    "\n",
    "offset = bar_width / 2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(index, shannon_entropy_np, bar_width, label='Shannon', alpha=0.6)\n",
    "ax.bar(index + bar_width, von_entropy_np, bar_width, label='Von-Neumann', alpha=0.6)\n",
    "\n",
    "ax.plot(index + offset, shannon_entropy_np, 'o-', label='Trend of Shannon')\n",
    "ax.plot(index + bar_width + offset, von_entropy_np, 's-', label='Trend of Von-Neumann')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Samples')\n",
    "ax.set_ylabel('Value')\n",
    "\n",
    "ax.set_title(args.data)\n",
    "\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quantum",
   "language": "python",
   "name": "quantum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
